{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with NLTK\n",
    "\n",
    "Natural Language Processing with the Natural Language Toolkit\n",
    "\n",
    "[nltk](http://www.nltk.org/) is a Python package for NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip install nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of NLTK depends on additional data which you'll have to download. Use `nltk.download()` to get at least the following:\n",
    "\n",
    " * maxent_treebank_pos_tagger (in models)\n",
    " * punkt (in models)\n",
    " * maxent_ne_chunk (in models)\n",
    " * words (in corpora)\n",
    "\n",
    "You can install these and continue without restarting your kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info http://www.nltk.org/nltk_data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello.',\n",
       " 'How are you, dear sir?',\n",
       " 'Are you well?',\n",
       " 'Here: drink this!',\n",
       " 'It will make you feel better.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"\"\"Hello. How are you, dear sir? Are you well?\n",
    "          Here: drink this! It will make you feel better.\"\"\"\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'will', 'make', 'you', 'feel', 'better', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(sentences[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'will', 'make', 'you', 'feel', 'better', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(sentences[4])\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you say \"word\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here', ':', 'drink', 'this', '!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Who', \"'s\", 'going', 'to', 'that', 'thing', 'today', '?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"Who's going to that thing today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Who', \"'\", 's', 'going', 'to', 'that', 'thing', 'today', '?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(\"Who's going to that thing today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo of different tokenizers: http://text-processing.com/demo/tokenize/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Who', 'WP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('going', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('that', 'DT'),\n",
       " ('thing', 'NN'),\n",
       " ('today', 'NN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "words = word_tokenize(\"Who's going to that thing today?\")\n",
    "pos_tag(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WP: wh-pronoun (\"who\", \"what\")  \n",
    "VBZ: verb, 3rd person sing. present (\"takes\")  \n",
    "VBG: verb, gerund/present participle (\"taking\")  \n",
    "TO: to (\"to go\", \"to him\")   \n",
    "DT: determiner (\"the\", \"this\")  \n",
    "NN: noun, singular or mass (\"door\")  \n",
    ".: Punctuation (\".\", \"?\")  \n",
    "\n",
    "All tags: http://www.monlp.com/2011/11/08/part-of-speech-tags/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of speech allows you to focus on different parts of language.\n",
    "\n",
    "You may want to find keywords only among verbs, for example.\n",
    "\n",
    "Or when you are classifying, you may want to use nouns and adjectives as features, because they carry the most information about the subject (compared to who tags like WP, or TO, etc.) Part of speech can allow you to do higher resolution text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "Extracting phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  'm/VBP\n",
      "  (PERSON Irmak/NNP Sirer/NNP)\n",
      "  and/CC\n",
      "  I/PRP\n",
      "  'm/VBP\n",
      "  here/RB\n",
      "  to/TO\n",
      "  say/VB\n",
      "  I/PRP\n",
      "  love/VBP\n",
      "  (ORGANIZATION NLTK/NNP)\n",
      "  in/IN\n",
      "  a/DT\n",
      "  major/JJ\n",
      "  way/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import ne_chunk\n",
    "words = word_tokenize(\"\"\"I'm Irmak Sirer and I'm here to say\n",
    "                         I love NLTK in a major way.\"\"\")\n",
    "tags = pos_tag(words)\n",
    "tree = ne_chunk(tags)\n",
    "print tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Included text corpora\n",
    "\n",
    "Also install these!\n",
    "\n",
    " * movie_reviews: Imdb reviews characterized as pos & neg  \n",
    " * treebank: tagged and parsed Wall Street Journal text  \n",
    " * brown: tagged & categorized English text (news, fiction, etc)  \n",
    "\n",
    "(There are over 60 others.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info http://www.nltk.org/nltk_data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Pierre', u'NNP'),\n",
       " (u'Vinken', u'NNP'),\n",
       " (u',', u','),\n",
       " (u'61', u'CD'),\n",
       " (u'years', u'NNS'),\n",
       " (u'old', u'JJ'),\n",
       " (u',', u','),\n",
       " (u'will', u'MD'),\n",
       " (u'join', u'VB'),\n",
       " (u'the', u'DT'),\n",
       " (u'board', u'NN'),\n",
       " (u'as', u'IN'),\n",
       " (u'a', u'DT'),\n",
       " (u'nonexecutive', u'JJ'),\n",
       " (u'director', u'NN'),\n",
       " (u'Nov.', u'NNP'),\n",
       " (u'29', u'CD'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import treebank_chunk\n",
    "treebank_chunk.tagged_sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treebank_chunk.chunked_sents()[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pip install textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "GATSBY_TEXT = \"\"\"In my younger and more vulnerable years my father\n",
    "                 gave me some advice that I've been turning over\n",
    "                 in my mind ever since. \"Whenever you feel like\n",
    "                 criticizing any one,\" he told me, \"blah blah blah.\"\"\"\n",
    "\n",
    "gatsby = TextBlob(GATSBY_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'In', u'IN'),\n",
       " (u'my', u'PRP$'),\n",
       " (u'younger', u'JJR'),\n",
       " (u'and', u'CC'),\n",
       " (u'more', u'JJR'),\n",
       " (u'vulnerable', u'JJ'),\n",
       " (u'years', u'NNS'),\n",
       " (u'my', u'PRP$'),\n",
       " (u'father', u'NN'),\n",
       " (u'gave', u'VBD'),\n",
       " (u'me', u'PRP'),\n",
       " (u'some', u'DT'),\n",
       " (u'advice', u'NN'),\n",
       " (u'that', u'IN'),\n",
       " (u'I', u'PRP'),\n",
       " (u\"'\", u'POS'),\n",
       " (u've', u'NN'),\n",
       " (u'been', u'VBN'),\n",
       " (u'turning', u'VBG'),\n",
       " (u'over', u'IN'),\n",
       " (u'in', u'IN'),\n",
       " (u'my', u'PRP$'),\n",
       " (u'mind', u'NN'),\n",
       " (u'ever', u'RB'),\n",
       " (u'since', u'IN'),\n",
       " (u'Whenever', u'WRB'),\n",
       " (u'you', u'PRP'),\n",
       " (u'feel', u'VB'),\n",
       " (u'like', u'IN'),\n",
       " (u'criticizing', u'VBG'),\n",
       " (u'any', u'DT'),\n",
       " (u'one', u'CD'),\n",
       " (u'he', u'PRP'),\n",
       " (u'told', u'VBD'),\n",
       " (u'me', u'PRP'),\n",
       " (u'blah', u'NN'),\n",
       " (u'blah', u'NN'),\n",
       " (u'blah', u'NN')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatsby.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList([u'vulnerable years', 'whenever', u'blah blah blah'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatsby.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.3333333333333333)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatsby.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.75, subjectivity=0.8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"Oh my god I love this bootcamp, it's so awesome.\").sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-1.0, subjectivity=1.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"Cupcakes are the worst.\").sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"The color of this car is blue\").sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8\n"
     ]
    }
   ],
   "source": [
    "print TextBlob(\"I hate cupcakes.\").sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "print TextBlob(\"I hate cupcakes.\").sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"In my younger and more vulnerable years my father\n",
       "                  gave me some advice that I've been turning over\n",
       "                  in my mind ever since.\"), Sentence(\"\"Whenever you feel like\n",
       "                  criticizing any one,\" he told me, \"blah blah blah.\")]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatsby.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['In', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'I', \"'ve\", 'been', 'turning', 'over', 'in', 'my', 'mind', 'ever', 'since', 'Whenever', 'you', 'feel', 'like', 'criticizing', 'any', 'one', 'he', 'told', 'me', 'blah', 'blah', 'blah'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatsby.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['In', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'I', \"'ve\", 'been', 'turning', 'over', 'in', 'my', 'mind', 'ever', 'since'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatsby.sentences[0].words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "wa\n",
      "go\n",
      "to\n",
      "go\n",
      "to\n",
      "mani\n",
      "place\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "for word in TextBlob(\"I was going to go to many places\").words:\n",
    "    print stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see different nltk stemmers in effect:\n",
    "http://text-processing.com/demo/stem/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            and 1\n",
      "             ve 1\n",
      "           feel 1\n",
      "           over 1\n",
      "           mind 1\n",
      "          years 1\n",
      "           blah 3\n",
      "             in 2\n",
      "            any 1\n",
      "     vulnerable 1\n",
      "          since 1\n",
      "         father 1\n",
      "           been 1\n",
      "            you 1\n",
      "           ever 1\n",
      "           gave 1\n",
      "        turning 1\n",
      "           that 1\n",
      "           some 1\n",
      "         advice 1\n",
      "            one 1\n",
      "             he 1\n",
      "             me 2\n",
      "        younger 1\n",
      "           like 1\n",
      "              i 1\n",
      "           told 1\n",
      "       whenever 1\n",
      "    criticizing 1\n",
      "           more 1\n",
      "             my 3\n"
     ]
    }
   ],
   "source": [
    "for word, count in gatsby.word_counts.items():\n",
    "    print \"%15s %i\" % (word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           blah 3\n",
      "             my 3\n",
      "             in 2\n",
      "             me 2\n",
      "            and 1\n",
      "             ve 1\n",
      "           feel 1\n",
      "           over 1\n",
      "           mind 1\n",
      "          years 1\n",
      "            any 1\n",
      "     vulnerable 1\n",
      "          since 1\n",
      "         father 1\n",
      "           been 1\n",
      "            you 1\n",
      "           ever 1\n",
      "           gave 1\n",
      "        turning 1\n",
      "           that 1\n",
      "           some 1\n",
      "         advice 1\n",
      "            one 1\n",
      "             he 1\n",
      "        younger 1\n",
      "           like 1\n",
      "              i 1\n",
      "           told 1\n",
      "       whenever 1\n",
      "    criticizing 1\n",
      "           more 1\n"
     ]
    }
   ],
   "source": [
    "def get_count(item):\n",
    "    return item[1]\n",
    "\n",
    "for word, count in sorted(gatsby.word_counts.items(), key=get_count, reverse=True):\n",
    "    print \"%15s %i\" % (word, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pprint import pprint\n",
    "client = pymongo.MongoClient()\n",
    "db = client.ds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print db.doge.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f009d14511d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"favorite_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"$gte\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "tweet = db.doge.find_one({\"favorite_count\": {\"$gte\": 10}})\n",
    "print(tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TextBlob(tweet['text']).words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word counts in doge tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_text = \"\"\n",
    "for tweet in db.doge.find().limit(100):\n",
    "    all_text += tweet[\"text\"] + \"\\n\"\n",
    "    \n",
    "for word, count in sorted(TextBlob(all_text).word_counts.items(), key=get_count, reverse=True)[:15]:\n",
    "    print \"%15s %i\" % (word, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "all_text = \"\"\n",
    "for tweet in db.doge.find().limit(100):\n",
    "    all_text += tweet[\"text\"] + \"\\n\"\n",
    "\n",
    "for word, count in sorted(TextBlob(all_text).word_counts.items(),\n",
    "                          key=get_count, reverse=True)[:20]:\n",
    "    if word not in stop:\n",
    "        print \"%15s %i\" % (word, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "fileids = movie_reviews.fileids()[:100]\n",
    "doc_words = [movie_reviews.words(fileid) for fileid in fileids]\n",
    "documents = [' '.join(words) for words in doc_words]\n",
    "print documents[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top bigrams in reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop += ['.', ',', '(', ')', \"'\", '\"']\n",
    "\n",
    "counter = defaultdict(int)\n",
    "\n",
    "n = 2\n",
    "for doc in documents:\n",
    "    words = TextBlob(doc).words\n",
    "    words = [w for w in words if w not in stop]\n",
    "    bigrams = ngrams(words, n)\n",
    "    for gram in bigrams:\n",
    "        counter[gram] += 1\n",
    "            \n",
    "for gram, count in sorted(counter.items(), key = itemgetter(1), reverse=True)[:30]:\n",
    "    phrase = \" \".join(gram)\n",
    "    print '%20s %i' % (phrase, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Sklearn algorithms with text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### TF: frequency in this document\n",
    "#### IDF: inverse frequency in the corpus\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2))\n",
    "doc_vectors = vectorizer.fit_transform(documents)\n",
    "\n",
    "classes = np.array(['pos']*50 + ['neg']*50)\n",
    "\n",
    "\n",
    "model = MultinomialNB().fit(doc_vectors, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gatsby_vector = vectorizer.transform([GATSBY_TEXT])\n",
    "model.predict(gatsby_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
