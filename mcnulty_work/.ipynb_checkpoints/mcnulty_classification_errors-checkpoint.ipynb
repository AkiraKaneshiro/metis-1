{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import csv\n",
    "import pickle\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "# randn = np.random.randn\n",
    "from pandas import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import linregress\n",
    "from pylab import *\n",
    "from urllib import urlopen\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Errors Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge 1\n",
    "\n",
    "For the house representatives data set, calculate the accuracy, precision, recall and f1 scores of each classifier you built (on the test set).\n",
    "\n",
    "Challenge 2\n",
    "\n",
    "For each, draw the ROC curve and calculate the AUC.\n",
    "\n",
    "Challenge 3\n",
    "\n",
    "Calculate the same metrics you did in challenge 1, but this time in a cross validation scheme with the cross_val_score function (like in Challenge 9).\n",
    "\n",
    "Challenge 4\n",
    "\n",
    "For your movie classifiers, calculate the precision and recall for each class.\n",
    "\n",
    "Challenge 5\n",
    "\n",
    "Draw the ROC curve (and calculate AUC) for the logistic regression classifier from challenge 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "y_true = np.array([0, 1, 2, 0, 1, 2])\n",
    "y_pred = np.array([0, 2, 1, 0, 0, 1])\n",
    "precision_recall_fscore_support(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
